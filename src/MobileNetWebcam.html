<!DOCTYPE html>
<html>

<head>

    <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.13.0"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.1.0/js/bootstrap.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <style>
        #wrapper {
            text-align: center;
            margin: 10px auto;
        }

        #overlay {
            width: 550px;
        }

        #output_image {
            width: 550px;
        }
        .inline {
            display: inline-block;
        }
    </style>
</head>

<body>
    <center style="padding:10px; margin:5px">
        <h4>
            <span id="status">Model Loading ...</span>
        </h4>
    </center>
    <center style="padding:10px">
        <button type="button" id='start' class="btn btn-outline-primary" onclick='startVideo()'>Start Therapy</button>
    </center>

    <audio style="display: none;" id="audio_track" class="my_audio" controls preload="none">
	    <source id='sound_src' type="audio/mpeg">
	    <!-- <source src="audio/my_song.ogg" type="audio/ogg"> -->
	</audio>
    
    <div class="inline">
        <center><span id="original_video"></span></center>
        <video id='video' width="500px"></video>
    </div>

    <div class="inline">
        <!--        <center><span id="emotion_video"></span></center>-->
        <canvas id="canvas" src="" style=" margin-top:10px;" />
    </div>
    <div id = "thank">
        <center style="padding:10px; margin:5px">
            <div>Done by TEAM CALLIOPE</div>
        </center>
    </div>
</body>
<script>
    // check using phone or not
    if (/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
        alert('Sorry, this website not support mobile divices currently.');
        history.back();
    }

    // check using chrome
    if (!window.chrome) {
        if (confirm('This website needs Chrome browser!!!')) {
            closewin();
        } else {
            history.back();
        }
    }

    var constraints = {
        video: true
    };

    var $body = document.querySelector('body');
    //    var status = document.getElementById('status');
    var emotion_labels = ["angry", "disgust", "fear", "happy", "sad", "surprise", "neutral"];
    var emotion_colors = ["#ff0000", "#00a800", "#ff4fc1", "#ffe100", "#306eff", "#ff9d00", "#7c7c7c"];
    var offset_x = 15;
    var offset_y = 40;
    var label_max = "";

    loadModel('../models/mobilenetv1_models/model.json')
    // create model
    async function createModel(path) {
        let model_tmp = await tf.loadModel(path)
        return model_tmp
    }

    // load models
    async function loadModel(path) {
        var status = document.getElementById('status');
        //        status.innerText = "Model Loading ..."
        model = await createModel(path)

        status.innerText = "Model Loaded !!!"
    }


    function createVideoElement() {
        let $video = document.createElement('video')
        $video.style.maxWidth = '100vw'
        $video.style.width = '100vw'
        $video.style.maxHeight = '0vh'
        $body.appendChild($video)
        return $video
    }

    function handleError(error) {
        if (error.name === 'DevicesNotFoundError') {
            alert('No camera detected. <br> Do you have any camera connected?');
        } else if (error.name === 'NotAllowedError') {
            alert('You have to allow camera access in order to run this experiment.');
        } else if (navigator.userAgent.indexOf('Chrome') > -1) {
            alert('Error. <br> Enable experimental features on chrome://flags/#enable-experimental-web-platform-features');
        } else {
            alert('Error. <br> Does your browser supports FaceDetector API?');
        }
        console.error(error)
    }

    function createCanvas(video) {

        const canvas = document.getElementById('canvas')
        const videoCompStyle = window.getComputedStyle(video)
        canvas.width = videoCompStyle.width.replace('px', '')
        canvas.height = videoCompStyle.height.replace('px', '')
        //        canvas.style.display = 'none'
        document.querySelector('body').appendChild(canvas)

        return canvas
    }

    function playMusic(label_max)
    {
    	if (label_max == "angry") 
    	{
    		$("#sound_src").attr("src", "./music/1.mp3")[0];
			$(".my_audio").trigger('load');
           	$(".my_audio").trigger('play');
    	}
    	else if (label_max == "disgust") 
    	{
    		$("#sound_src").attr("src", "./music/2.mp3")[0];
			$(".my_audio").trigger('load');
           	$(".my_audio").trigger('play');
    	}
    	else if (label_max == "fear") 
    	{
    		$("#sound_src").attr("src", "./music/3.mp3")[0];
			$(".my_audio").trigger('load');
           	$(".my_audio").trigger('play');
    	}
    	else if (label_max == "happy") 
    	{
    		$("#sound_src").attr("src", "./music/4.mp3")[0];
			$(".my_audio").trigger('load');
           	$(".my_audio").trigger('play');
    	}
    	else if (label_max == "sad") 
    	{
    		$("#sound_src").attr("src", "./music/1.mp3")[0];
			$(".my_audio").trigger('load');
           	$(".my_audio").trigger('play');
    	}
    	else if (label_max == "surprise") 
    	{
    		$("#sound_src").attr("src", "./music/3.mp3")[0];
			$(".my_audio").trigger('load');
           	$(".my_audio").trigger('play');
    	}
    	else if (label_max == "neutral") 
    	{
    		$("#sound_src").attr("src", "./music/2.mp3")[0];
			$(".my_audio").trigger('load');
           	$(".my_audio").trigger('play');
    	}
    	
    }

    function createDrawFunction() {

        const faceDetector = new window.FaceDetector({
            maxDetectedFaces: 3
        })
        let isDetectingFaces = false
        let faces = []
        let hideTimeout
        // console.log("Inside Create Draw Function");
        
        $(".my_audio").trigger('pause');
        $(".my_audio").prop("currentTime",0);

        let no = 100;
        let angry = 0;
        let disgust= 0;
        let fear = 0; 
        let happy=0;
        let  sad=0;
        let surprise=0;
        let neutral=0;
        let max = 0;
        label_max = "";
        return async function draw(canvas, video) {
       if (no>0) {
            window.requestAnimationFrame(() => draw(canvas, video))
            
            const context = canvas.getContext('2d')
            const videoCompStyle = window.getComputedStyle(video)
            const videoWidth = videoCompStyle.width.replace('px', '')
            const videoHeight = videoCompStyle.height.replace('px', '')
            context.drawImage(video, 0, 0, videoWidth, videoHeight)
            
            if (faces.length) {

                let ctx = context;
                
                // console.log("Inside IF")
                ctx.lineWidth = 4;
                ctx.font = "20px Arial"
                ctx.fillText('Result', 0, 0);
                for (var i = 0; i < faces.length; i++) {
                    ctx.beginPath();
                    var item = faces[i].boundingBox;
                    //                    console.log(item)
                    let s_x = Math.floor(item.x - offset_x / 2);
                    let s_y = Math.floor(item.y - offset_y / 2);
                    let s_w = Math.floor(item.width + offset_x);
                    let s_h = Math.floor(item.height + offset_y);

                    let cT = ctx.getImageData(s_x, s_y, s_w, s_h);
                    cT = preprocess(cT);
                    z = model.predict(cT)

                    let index = z.argMax(1).dataSync()[0]
                    let label = emotion_labels[index];

                    console.log(label);
                    if (label == "angry")
                    	angry+=1;
                    else if (label == "disgust")
                    	disgust+=1
                   	else if (label == "fear")
                    	fear+=1
                    else if (label == "happy")
                    	happy+=1
                    else if (label == "sad")
                    	sad+=1
                    else if (label == "surprise")
                    	surprise+=1
                    else if (label == "neutral")
                    	neutral+=1
                    ctx.strokeStyle = emotion_colors[index];
                    ctx.rect(s_x, s_y, s_w, s_h);
                    ctx.stroke();
                    ctx.fillStyle = emotion_colors[index];
                    ctx.fillText(label, s_x, s_y);
                    ctx.closePath();
                }
            } else {
                console.log('NO FACE')
                //                status.innerHTML = "NO FACE";
            }

            if (isDetectingFaces) {
                return
            }

            isDetectingFaces = true
            faces = await faceDetector.detect(canvas)
            isDetectingFaces = false
            var status = document.getElementById('status');
            status.innerHTML = "Running the model ... ";
        }
        no -=1;
        if (no==0) 
        {
   			     // finding max one:-
			    if (max<disgust)
			    {
			    	max = disgust;
			    	label_max = "disgust";
			    }
			    if (max<angry)
			    {
			    	max = angry;
			    	label_max = "angry";
			    }
				if (max<fear)
				{
			    	label_max = "fear";
			    	max = fear;
				}
			    if (max<happy)
			    {
			    	max = happy;
			    	label_max = "happy";
			    }
			    if (max<sad)
			    {
			    	label_max = "sad";
			    	max = sad;
			    }
			    if (max<surprise)
			    {
			    	label_max = "surprise";
			    	max = surprise;
			    }
			    if (max<neutral)
			    {
			    	label_max = "neutral";
			    	max = neutral;
			    }
			    console.log("Max emotion is ",max," ",label_max);
			    if (max!=0) 
			    {
				    var x = document.getElementById("audio_track");
    	    		x.style.display = "block";
        
				    playMusic(label_max);

			    }
				    var delayInMilliseconds = 5000; //5 second

					setTimeout(function() {
						startVideo();
					}, delayInMilliseconds);			    	
        }        
    	
    }
   

    }

    function preprocess(imgData) {
        return tf.tidy(() => {
            let tensor = tf.fromPixels(imgData).toFloat();

            tensor = tensor.resizeBilinear([100, 100])

            tensor = tf.cast(tensor, 'float32')
            const offset = tf.scalar(255.0);
            // Normalize the image 
            const normalized = tensor.div(offset);
            //We add a dimension to get a batch shape 
            const batched = normalized.expandDims(0)
            return batched
        })
    }


    function playCameraOnVideo(video) {
        return navigator.mediaDevices.getUserMedia({
                video: {
                    facingMode: 'user',
                    frameRate: 60
                },
                audio: false
            })
            .then(srcObject => video.srcObject = srcObject)
            .then(() => video.play())
    }

    async function main(video) {
        const video_canvas = createCanvas(video)
        const draw = createDrawFunction()
        draw(video_canvas, video)
    }

    function startVideo() {
        var x = document.getElementById("thank");
        x.style.display = "none";
        var x = document.getElementById("audio_track");
        x.style.display = "none";
        let elem = document.getElementById('start');
        // elem.parentNode.removeChild(elem);
        elem.style.display = "none";

        var status = document.getElementById('status');
        status.innerHTML = "Initializing the camera ... ";

        var ori = document.getElementById("original_video");
        //        var emo = document.getElementById("emotion_video");
        ori.innerHTML = "Original: "
        
        playCameraOnVideo(video)
	            .then(() => main(video))
	            .catch(handleError)        	
        
    }
</script>

</html>